import sys
import asyncio

if sys.platform == "win32":
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

import sys

import cv2

import streamlit as st

import os
os.environ["STREAMLIT_SERVER_ENABLE_WATCH_DOG"] = "false"
ROOT = os.path.dirname(os.path.abspath(__file__))

# æ·»åŠ è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .stApp { background-color: #f5f5f5; }
    .stButton>button {
        background-color: #4CAF50;
        color: white;
        border-radius: 5px;
        padding: 0.5rem 1rem;
        transition: all 0.3s;
    }
    .stButton>button:hover {
        background-color: #45a049;
        transform: scale(1.05);
    }
    .stDownloadButton>button {
        background-color: #008CBA !important;
    }
    .result-box {
        padding: 1rem;
        background-color: white;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)


from app_data.dependencies.utils import IMG_SIZE, bilinear_unwarping, load_model
from app_data.dependencies.streamlit_utils import load_yolo_model, unwarp_img, plot_results, perform_ocr


def main():
    st.title("æ™ºèƒ½æ–‡æ¡£å¤„ç†ç³»ç»Ÿ")
    st.markdown("---")

    # åˆå§‹åŒ–æ¨¡å‹
    with st.spinner("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹..."):
        # model_path = os.path.join(
        #     r"E:\PythonProject1\UVDoc-main\myfile\visualize\app_data\models\unwrap_model\best_model.pkl")
        model_path = os.path.join(ROOT,"app_data/models/unwrap_model/best_model.pkl")
        model = load_model(model_path)
        # yolo_model_path = os.path.join(
        #     r"E:\PythonProject1\UVDoc-main\myfile\visualize\app_data\models\cls_model\best.pt")
        yolo_model_path = os.path.join(ROOT,"app_data/models/cls_model/best.pt")
        yolo_model = load_yolo_model(yolo_model_path)

    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("é…ç½®é€‰é¡¹")
        model_folder = os.path.join(ROOT,"app_data/models/unwrap_model")
        model_files = [f for f in os.listdir(model_folder)]
        selected_model = st.selectbox("é€‰æ‹©æ ¡æ­£æ¨¡å‹", model_files, index=0)
        selected_model_path = os.path.join(model_folder, selected_model)

        st.markdown("---")
        ocr_prompt = st.text_input("OCRæç¤ºè¯",
                                   value="è¯·æå–å¹¶è¾“å‡ºå›¾åƒä¸­çš„æ‰€æœ‰æ–‡å­—ï¼ŒåŒ…æ‹¬æ‰‹å†™æ–‡å­—ã€å°åˆ·æ–‡å­—ä»¥åŠå¯èƒ½å­˜åœ¨çš„å¤šè¯­è¨€æ–‡å­—ã€‚è¾“å‡ºæ—¶è¯·ç¡®ä¿æ–‡å­—çš„å®Œæ•´æ€§å’Œå¯è¯»æ€§ã€‚å¦‚æœå›¾åƒä¸­å­˜åœ¨æ¨¡ç³Šæˆ–éš¾ä»¥è¯†åˆ«çš„æ–‡å­—ï¼Œè¯·å°½é‡æä¾›å¯èƒ½çš„æ¨æµ‹ç»“æœ",
                                   help="è¾“å…¥ç»™OCRæ¨¡å‹çš„æç¤ºæŒ‡ä»¤")
        st.markdown("---")
        st.info("ä½¿ç”¨è¯´æ˜ï¼š\n1. ä¸Šä¼ å›¾ç‰‡\n2. é€‰æ‹©å¤„ç†åŠŸèƒ½\n3. æŸ¥çœ‹ç»“æœ")

    # ä¸»å†…å®¹åŒºåŸŸ
    uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡æ¡£å›¾ç‰‡", type=["png", "jpg", "jpeg"],
                                     help="æ”¯æŒPNG/JPG/JPEGæ ¼å¼")

    if uploaded_file is not None:
        # ä¿å­˜ä¸Šä¼ çš„å›¾ç‰‡
        original_img_path = os.path.join(ROOT,"app_data/log/temp.png")
        with open(original_img_path, "wb") as f:
            f.write(uploaded_file.getvalue())

        # ä¸‰åˆ—å¸ƒå±€å®¹å™¨
        col1, col2, col3 = st.columns(3)

        # ç¬¬ä¸€åˆ—ï¼šåŸå§‹å›¾ç‰‡
        with col1:
            st.subheader("åŸå§‹å›¾ç‰‡")
            st.image(uploaded_file,
                     use_column_width=True,
                     caption="ä¸Šä¼ çš„åŸå§‹æ–‡æ¡£å›¾ç‰‡")



        # ç¬¬ä¸‰åˆ—ï¼šæ£€æµ‹ç»“æœ
        with col2:
            st.subheader("æ£€æµ‹åˆ†æ")
            if "annotated_img" in st.session_state:
                st.image(st.session_state.annotated_img,
                         channels="BGR",
                         use_column_width=True,
                         caption="æ–‡æ¡£æ£€æµ‹ç»“æœ",
                         output_format="PNG")
                # åˆ†æè¯¦æƒ…é¢æ¿
                # with st.expander("ğŸ“Š æ£€æµ‹è¯¦æƒ…"):
                #     st.code("æ£€æµ‹ç½®ä¿¡åº¦ï¼š92%\nåˆ†ç±»ç»“æœï¼šæ­£å¼åˆåŒæ–‡æ¡£")
            else:
                st.info("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®è¿›è¡Œæ–‡æ¡£æ£€æµ‹")

        # ç¬¬äºŒåˆ—ï¼šæ ¡æ­£ç»“æœ
        with col3:
            st.subheader("æ ¡æ­£ç»“æœ")
            if "processed_img_path" in st.session_state:
                st.image(st.session_state.processed_img_path,
                         use_column_width=True,
                         caption="æ–‡æ¡£æ ¡æ­£ç»“æœ")
                # ä¸‹è½½æŒ‰é’®
                with open(st.session_state.processed_img_path, "rb") as f:
                    img_bytes = f.read()
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½æ ¡æ­£ç»“æœ",
                    data=img_bytes,
                    file_name="corrected_document.png",
                    mime="image/png",
                    use_container_width=True
                )
            else:
                st.info("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®è¿›è¡Œæ–‡æ¡£æ ¡æ­£")

        # åŠŸèƒ½æŒ‰é’®åŒºåŸŸ
        st.markdown("---")
        btn_col1, btn_col2, _ = st.columns([1, 1, 4])
        with btn_col1:
            if st.button("æ–‡æ¡£æ ¡æ­£", help="è¿›è¡Œæ–‡æ¡£å‡ ä½•æ ¡æ­£å¤„ç†"):
                with st.spinner("æ­£åœ¨æ ¡æ­£æ–‡æ¡£..."):
                    try:
                        processed_path = unwarp_img(selected_model_path, original_img_path, IMG_SIZE, model)
                        st.session_state.processed_img_path = processed_path
                        st.rerun()
                    except Exception as e:
                        st.error(f"æ ¡æ­£å¤±è´¥: {str(e)}")

        with btn_col2:
            if st.button("æ–‡æ¡£æ£€æµ‹", help="è¿›è¡Œæ–‡æ¡£åˆ†ç±»æ£€æµ‹"):
                if yolo_model is not None:
                    with st.spinner("æ­£åœ¨åˆ†ææ–‡æ¡£..."):
                        try:
                            results = yolo_model(original_img_path)
                            annotated_img = plot_results(cv2.imread(original_img_path), results)
                            st.session_state.annotated_img = annotated_img
                            st.rerun()
                        except Exception as e:
                            st.error(f"æ£€æµ‹å¤±è´¥: {str(e)}")

        # # OCRåŠŸèƒ½åŒºåŸŸ
        # st.markdown("---")
        # if st.button("ğŸ“– æ‰§è¡ŒOCRè¯†åˆ«", use_container_width=True):
        #     if "processed_img_path" in st.session_state:
        #         with st.spinner("æ­£åœ¨è¯†åˆ«æ–‡å­—..."):
        #             ocr_result = perform_ocr(ocr_prompt, st.session_state.processed_img_path)
        #             st.session_state.ocr_result = ocr_result
        #             st.rerun()
        #
        # if "ocr_result" in st.session_state:
        #     st.subheader("OCRè¯†åˆ«ç»“æœ")
        #     with st.container():
        #         st.markdown(f'<div class="result-box">{st.session_state.ocr_result}</div>',
        #                     unsafe_allow_html=True)
        #         if st.button("ğŸ“‹ å¤åˆ¶åˆ°å‰ªè´´æ¿", use_container_width=True):
        #             js = f"""
        #             navigator.clipboard.writeText(`{st.session_state.ocr_result}`);
        #             setTimeout(() => alert("å¤åˆ¶æˆåŠŸï¼"), 100);
        #             """
        #             html = f'<script>{js}</script>'
        #             st.components.v1.html(html, height=0)


if __name__ == "__main__":
    main()